# Global configuration  (copy this file to .env and adjust values as needed)
# All resource amount (e.g. memory cpu) should be lower then the system capability and lower than the amount docker is permitted to use

# Comma-separated list of models to download at startup. See available models at https://ollama.com/library
OLLAMA_MODEL_LIST=deepseek-r1:latest,deepseek-coder-v2:16b,deepseek-r1:14b,deepseek-r1:32b,qwen2.5-coder:32b

# CPU core allocation for Ollama (can be fractional)
OLLAMA_CPUS=10.0
# Memory allocation for Ollama processes in gigabytes (e.g., 38G = 38GB)
OLLAMA_MEMORY=38G

# Port settings for Ollama and web services
OLLAMA_PORT=11434
SEARXNG_PORT=8081
OPEN_WEBUI_PORT=3000

# Caddy/SearxNg configuration
SEARXNG_HOSTNAME=example.com  # Domain name used by SearxNg service (modify to your domain)
LETSENCRYPT_EMAIL=your-email@example.com  # Email for Let's Encrypt certificate generation
SEARXNG_UWSGI_WORKERS=10  # Number of uWSGI workers for SearxNg
SEARXNG_UWSGI_THREADS=10  # Number of threads per worker
SEARXNG_CORE_CPUS=2  # CPU cores allocated to core components
SEARXNG_CORE_MEMORY=256M  # Memory allocation for core components (e.g., 256MB)
SEARXNG_CPUS=4  # Total CPu cores allocated for SearxNg service
SEARXNG_MEMORY=2048M  # Total memory allocated for SearxNg service (2GB)

# Open WebUI configuration
OPEN_WEBUI_CPUS=2  # CPU cores allocated to the web interface
OPEN_WEBUI_MEMORY=2048M  # Memory allocation for the web interface (2GB)
ENABLE_RAG_WEB_SEARCH=true  # Enable/disable web search integration

# Ollama GPU configuration (check docker's gpu support on your system)
OLLAMA_GPU_COUNT=all  # Use all available GPUs, adjust number if needed (e.g., "1" = single GPU)
GPU_DRIVER=nvidia  # NVIDIA GPU driver in use
